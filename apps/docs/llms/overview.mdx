---
title: "LLM Support"
description: "Language models supported by SpinAI"
---

SpinAI supports multiple LLMs for agent decision making:

- [OpenAI](/llms/openai)
- [Anthropic](/llms/anthropic)
- [Cloudflare](/llms/cloudflare)
- [Custom HTTP LLM](/llms/http-llm)

Each LLM can be configured with custom settings like:

- Model selection
- Temperature
- Token limits
- API configuration

## Choosing an LLM

Consider these factors when choosing an LLM:

- Cost per token
- Response quality
- API reliability
- Token context limits

## Cloudflare Integration

SpinAI now includes support for Cloudflare's LLM, offering a robust and scalable solution for your AI needs. Cloudflare's LLM can be easily integrated with your SpinAI projects, providing high-quality responses and reliable performance.

## Custom HTTP LLM Integration

For those requiring a more tailored solution, SpinAI also supports integration with custom HTTP-based LLMs. This allows you to leverage your own or third-party language models, providing the flexibility to meet specific project requirements.

## Next Steps

<CardGroup>
  <Card title="OpenAI Setup" icon="openai" href="/llms/openai">
    Use OpenAI models
  </Card>
  <Card title="Anthropic Setup" icon="brain" href="/llms/anthropic">
    Use Claude models
  </Card>
  <Card title="Cloudflare Setup" icon="cloud" href="/llms/cloudflare">
    Use Cloudflare models
  </Card>
  <Card title="Custom HTTP LLM Setup" icon="custom" href="/llms/http-llm">
    Configure your custom HTTP LLM
  </Card>
</CardGroup>

Related Documentation:
- [Cloudflare LLM Setup](/llms/cloudflare)
- [Custom HTTP LLM Setup](/llms/http-llm)