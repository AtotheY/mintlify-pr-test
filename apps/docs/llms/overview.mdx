---
title: "LLM Support"
description: "Language models supported by SpinAI"
---

SpinAI supports multiple LLMs for agent decision making:

- [OpenAI](/llms/openai)
- [Anthropic](/llms/anthropic)
- [Cloudflare](/llms/cloudflare)
- Custom HTTP-based LLMs

Each LLM can be configured with custom settings like:

- Model selection
- Temperature
- Token limits
- API configuration

## Choosing an LLM

Consider these factors when choosing an LLM:

- Cost per token
- Response quality
- API reliability
- Token context limits

## Cloudflare AI Integration

SpinAI now supports Cloudflare's AI models, allowing you to leverage Cloudflare's LLaMA models for your agent's decision-making processes. To use Cloudflare AI, you need to configure it with your API token and account ID. Optionally, you can specify the model you want to use; otherwise, it defaults to `@cf/meta/llama-2-7b-chat-int8`.

```typescript
import { createCloudflareAILLM } from 'spinai/llms/cloudflare';

const cloudflareConfig = {
  apiToken: 'your_cloudflare_api_token',
  accountId: 'your_cloudflare_account_id',
  model: '@cf/meta/llama-2-7b-chat-int8', // Optional
};

const cloudflareLLM = createCloudflareAILLM(cloudflareConfig);
```

## Custom HTTP LLMs

For greater flexibility, SpinAI also supports custom HTTP-based LLMs. This allows you to integrate any AI model that can be accessed over HTTP by configuring the endpoint and, optionally, API keys, headers, and request/response transformations.

```typescript
import { createHttpLLM } from 'spinai/llms/http';

const httpLLMConfig = {
  endpoint: 'https://your.custom.ai.endpoint',
  apiKey: 'optional_api_key',
  headers: {
    'Custom-Header': 'Value',
    // Additional headers
  },
  transformRequest: (body) => {
    // Optionally transform the request body
    return body;
  },
  transformResponse: (response) => {
    // Optionally transform the response to a string
    return response;
  },
};

const httpLLM = createHttpLLM(httpLLMConfig);
```

## Next Steps

<CardGroup>
  <Card title="OpenAI Setup" icon="openai" href="/llms/openai">
    Use OpenAI models
  </Card>
  <Card title="Anthropic Setup" icon="brain" href="/llms/anthropic">
    Use Claude models
  </Card>
  <Card title="Cloudflare Setup" icon="cloud" href="/llms/cloudflare">
    Use Cloudflare models
  </Card>
  <Card title="Custom HTTP LLM Setup" icon="code" href="/llms/custom-http">
    Configure your custom HTTP LLM
  </Card>
</CardGroup>