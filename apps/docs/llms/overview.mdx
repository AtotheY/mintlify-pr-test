```mdx
---
title: "LLM Support"
description: "Language models supported by SpinAI"
---

SpinAI supports multiple LLMs for agent decision making:

- [OpenAI](/llms/openai)
- [Anthropic](/llms/anthropic)
- [Cloudflare](/llms/cloudflare) <!-- New addition -->
- Custom HTTP LLM <!-- New addition -->

Each LLM can be configured with custom settings like:

- Model selection
- Temperature
- Token limits
- API configuration

## Choosing an LLM

Consider these factors when choosing an LLM:

- Cost per token
- Response quality
- API reliability
- Token context limits

## Cloudflare AI LLM <!-- New section -->

Cloudflare AI LLM allows you to use Cloudflare's AI models for generating text. You must provide your Cloudflare API token and account ID to use this service. The default model used is `@cf/meta/llama-2-7b-chat-int8`, but you can specify other models in the configuration.

```typescript
import { createCloudflareAILLM } from 'spinai/llms/cloudflare';

const cloudflareConfig = {
  apiToken: 'your_cloudflare_api_token',
  accountId: 'your_cloudflare_account_id',
  model: '@cf/meta/llama-2-7b-chat-int8', // Optional
};

const cloudflareLLM = createCloudflareAILLM(cloudflareConfig);
```

## Custom HTTP LLM <!-- New section -->

For integrating custom language models via HTTP, SpinAI provides an interface to configure endpoints, headers, and transformations for requests and responses. This is useful for connecting to proprietary or third-party LLMs not directly supported by SpinAI.

```typescript
import { createHttpLLM } from 'spinai/llms/http';

const httpLLMConfig = {
  endpoint: 'your_custom_http_endpoint',
  apiKey: 'optional_api_key',
  headers: {
    'Custom-Header': 'value', // Optional
  },
  transformRequest: (body) => {
    // Optional transformation of the request body
    return body;
  },
  transformResponse: (response) => {
    // Optional transformation of the response
    return response;
  },
};

const httpLLM = createHttpLLM(httpLLMConfig);
```

## Next Steps

<CardGroup>
  <Card title="OpenAI Setup" icon="openai" href="/llms/openai">
    Use OpenAI models
  </Card>
  <Card title="Anthropic Setup" icon="brain" href="/llms/anthropic">
    Use Claude models
  </Card>
  <Card title="Cloudflare Setup" icon="cloud" href="/llms/cloudflare">
    Use Cloudflare models
  </Card>
  <Card title="Custom HTTP Setup" icon="custom" href="/llms/custom-http">
    Configure Custom HTTP LLM
  </Card>
</CardGroup>

```