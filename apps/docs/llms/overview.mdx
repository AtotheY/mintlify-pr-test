```mdx
---
title: "LLM Support"
description: "Language models supported by SpinAI"
---

SpinAI supports multiple LLMs for agent decision making:

- [OpenAI](/llms/openai)
- [Anthropic](/llms/anthropic)
- [Cloudflare](/llms/cloudflare) {/* New addition */}
- Custom HTTP Endpoints {/* New addition */}

Each LLM can be configured with custom settings like:

- Model selection
- Temperature
- Token limits
- API configuration

## Choosing an LLM

Consider these factors when choosing an LLM:

- Cost per token
- Response quality
- API reliability
- Token context limits

## Cloudflare AI Integration {/* New section */}

SpinAI now includes support for Cloudflare's AI models. To use Cloudflare AI, you need to configure it with your API token and account ID. Optionally, you can specify the model you want to use; otherwise, the default model will be used.

```typescript
import { createCloudflareAILLM } from 'spinai/src/llms/cloudflare';

const cloudflareConfig = {
  apiToken: 'your_cloudflare_api_token',
  accountId: 'your_cloudflare_account_id',
  model: '@cf/meta/llama-2-7b-chat-int8', // Optional
};

const cloudflareLLM = createCloudflareAILLM(cloudflareConfig);
```

## Custom HTTP Endpoints Integration {/* New section */}

For integrating custom AI models via HTTP endpoints, SpinAI provides a flexible solution. You can specify the endpoint, optional API key, custom headers, and functions to transform the request and response.

```typescript
import { createHttpLLM } from 'spinai/src/llms/http';

const httpLLMConfig = {
  endpoint: 'your_custom_http_endpoint',
  apiKey: 'optional_api_key', // Optional
  headers: { 'Custom-Header': 'value' }, // Optional
  transformRequest: (body) => {/* transform logic */}, // Optional
  transformResponse: (response) => {/* transform logic */}, // Optional
};

const httpLLM = createHttpLLM(httpLLMConfig);
```

## Next Steps

<CardGroup>
  <Card title="OpenAI Setup" icon="openai" href="/llms/openai">
    Use OpenAI models
  </Card>
  <Card title="Anthropic Setup" icon="brain" href="/llms/anthropic">
    Use Claude models
  </Card>
  <Card title="Cloudflare Setup" icon="cloud" href="/llms/cloudflare"> {/* New addition */}
    Use Cloudflare models
  </Card>
  <Card title="Custom HTTP Setup" icon="gear" href="/llms/custom-http"> {/* New addition */}
    Use custom HTTP endpoints
  </Card>
</CardGroup>

```