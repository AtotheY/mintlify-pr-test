@@ -0,0 +1,98 @@
+import { LLM, CompletionOptions, CompletionResult } from "./base";
+import { calculateCost } from "../utils/tokenCounter";
+
+export interface CloudflareConfig {
+  apiToken: string;
+  accountId: string;
+  model?: string;
+}
+export function createCloudflareAILLM(config: CloudflareConfig): LLM {
+  if (!config.apiToken) {
+    throw new Error(
+      "Cloudflare API token is required. Please set CLOUDFLARE_API_TOKEN in your environment variables."
+    );
+  }
+
+  if (!config.accountId) {
+    throw an Error(
+      "Cloudflare Account ID is required. Please set CLOUDFLARE_ACCOUNT_ID in your environment variables."
+    );
+  }
+
+  The default model is "@cf/meta/llama-2-7b-chat-int8"; a custom model can be used. The function initiates a Cloudflare AI request with provided parameters, handles the response, estimates token costs based on character count, and provides error handling for failed requests.