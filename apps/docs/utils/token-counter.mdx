---
title: Token Counter Utility
description: Learn how to use the tokenCounter utility to estimate the cost of using different language models based on token usage.
---

## Overview

The `tokenCounter` utility is designed to help developers estimate the cost of using various language models by calculating the number of tokens generated by their input and output. This utility supports a wide range of models, including those from OpenAI, Anthropic, and now Cloudflare AI Models, making it a versatile tool for projects utilizing language model APIs.

## New Cost Estimation Feature

With the latest update, `tokenCounter` has expanded its capabilities to include cost estimation for Cloudflare AI Models and a custom HTTP model. This feature allows developers to better manage and predict the costs associated with using these models by understanding the token consumption for both input and output operations.

The cost estimation is based on predefined token costs for each model, which are as follows:

- **Cloudflare AI Models:**
  - `@cf/meta/llama-2-7b-chat-int8`: 0.2 tokens per input, 0.4 tokens per output
  - `@cf/meta/llama-2-13b-chat-int8`: 0.4 tokens per input, 0.8 tokens per output
  - `@cf/meta/llama-2-70b-chat-int8`: 1.0 tokens per input, 2.0 tokens per output
  - `@cf/mistral/mistral-7b-instruct-v0.1`: 0.2 tokens per input, 0.4 tokens per output
  - `@cf/tiiuae/falcon-7b-instruct`: 0.2 tokens per input, 0.4 tokens per output
  - `@cf/anthropic/claude-instant-1.2`: 0.8 tokens per input, 2.4 tokens per output
  - `@cf/anthropic/claude-2.1`: 8.0 tokens per input, 24.0 tokens per output

- **Custom HTTP Model:**
  - `custom-http-model`: 0.5 tokens per input, 1.5 tokens per output

This addition ensures that developers can accurately estimate the costs of using these models in their applications, aiding in budget management and cost optimization.

## How to Use

To use the `tokenCounter` for cost estimation, you need to specify the model ID and the text for which you want to count the tokens. The utility will then calculate the total cost based on the number of input and output tokens.

```typescript
import { tokenCounter } from 'path/to/tokenCounter';

const modelId = '@cf/meta/llama-2-7b-chat-int8'; // Example model ID
const text = 'Your input text here';

const { inputTokens, outputTokens, totalCost } = tokenCounter(modelId, text);

console.log(`Input Tokens: ${inputTokens}, Output Tokens: ${outputTokens}, Total Cost: ${totalCost}`);
```

This function will return the number of input tokens, output tokens, and the total cost based on the predefined token costs for the specified model. It simplifies the process of estimating how much it will cost to process a given piece of text with a specific model, allowing for more efficient budgeting and resource allocation.

Remember to replace `'path/to/tokenCounter'` with the actual path to the `tokenCounter` utility in your project.

## Conclusion

The updated `tokenCounter` utility is an essential tool for developers working with language models, providing a straightforward way to estimate costs associated with token usage. By incorporating cost estimation for Cloudflare AI Models and a custom HTTP model, it offers broader support and flexibility for projects of all sizes.